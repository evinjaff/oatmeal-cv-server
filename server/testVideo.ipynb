{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evinjaff/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBackgroundText(image, x, y, text, foreground_color, size, thickness):\n",
    "    (label_width, label_height), baseline = cv2.getTextSize(\n",
    "        text, cv2.FONT_HERSHEY_SIMPLEX, size, thickness\n",
    "    )\n",
    "\n",
    "    cv2.rectangle(\n",
    "        image,\n",
    "        (x // 2 - label_width // 2, y),\n",
    "        (x // 2 + label_width // 2, y - label_height),\n",
    "        (0, 0, 0),\n",
    "        -1,\n",
    "    )\n",
    "\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text,\n",
    "        (x // 2 - label_width // 2, y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        size,\n",
    "        foreground_color,\n",
    "        thickness,\n",
    "        cv2.LINE_AA,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 tongs, 1 bowl, 1 pan, 1 pepper, 1 measuring_cup_glass, 1 small_spoon, 285.9ms\n",
      "Speed: 1.9ms preprocess, 285.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(\n",
    "    \"/Users/evinjaff/github/oatmeal-cv-server/server/add_005.jpg\"\n",
    ")\n",
    "\n",
    "w = int(frame.shape[1])\n",
    "h = int(frame.shape[0])\n",
    "\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "finalImg = frame\n",
    "\n",
    "# get prediction\n",
    "predictionObject = model(frame)\n",
    "\n",
    "for allPreds in predictionObject:\n",
    "    for pred in allPreds:\n",
    "        if np.array(pred.boxes.conf)[0] < 0.7:\n",
    "            pass\n",
    "\n",
    "        # get label\n",
    "        labelNum = np.array(pred.boxes.cls)[0]\n",
    "        labelName = allPreds.names[labelNum]\n",
    "\n",
    "        # change item foundDictionaries to true\n",
    "        if labelName in allRequired.keys():\n",
    "            allRequired[labelName] = True\n",
    "        if labelName in allDistractors.keys():\n",
    "            allDistractors[labelName] = True\n",
    "\n",
    "        # Draw bounding box for object\n",
    "        box = np.array(pred.boxes.xyxy).flatten().astype(int)\n",
    "        # randomColor = tuple(np.random.random(size=3) * 256)\n",
    "        randomColor = (0,255,0)\n",
    "        cv2.rectangle(\n",
    "            finalImg,\n",
    "            (box[0], box[1]),\n",
    "            (box[2], box[3]),\n",
    "            randomColor,\n",
    "            4,\n",
    "        )\n",
    "        (label_width, label_height), baseline = cv2.getTextSize(\n",
    "            f\"{labelName}: {round(float(np.array(pred.boxes.conf)[0]), 2)}\",\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            2,\n",
    "        )\n",
    "        cv2.rectangle(\n",
    "            finalImg,\n",
    "            (box[0], box[1]),\n",
    "            (box[0] + label_width, box[1] - label_height),\n",
    "            randomColor,\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            finalImg,\n",
    "            f\"{labelName}: {round(float(np.array(pred.boxes.conf)[0]), 2)}\",\n",
    "            (box[0], box[1]),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0, 0, 0),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "\n",
    "cv2.imwrite('image.png', finalImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x640 (no detections), 218.3ms\n",
      "Speed: 1.6ms preprocess, 218.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 200.3ms\n",
      "Speed: 1.3ms preprocess, 200.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 213.3ms\n",
      "Speed: 1.2ms preprocess, 213.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 235.5ms\n",
      "Speed: 1.9ms preprocess, 235.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 235.8ms\n",
      "Speed: 1.4ms preprocess, 235.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 246.3ms\n",
      "Speed: 2.2ms preprocess, 246.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 236.0ms\n",
      "Speed: 1.7ms preprocess, 236.0ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 237.4ms\n",
      "Speed: 2.5ms preprocess, 237.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 239.5ms\n",
      "Speed: 2.2ms preprocess, 239.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 237.9ms\n",
      "Speed: 1.7ms preprocess, 237.9ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 239.4ms\n",
      "Speed: 3.2ms preprocess, 239.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 hot_pad, 221.9ms\n",
      "Speed: 1.8ms preprocess, 221.9ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 bowl, 254.1ms\n",
      "Speed: 2.2ms preprocess, 254.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 bowl, 239.0ms\n",
      "Speed: 2.5ms preprocess, 239.0ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 bowl, 253.0ms\n",
      "Speed: 1.8ms preprocess, 253.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 236.5ms\n",
      "Speed: 1.7ms preprocess, 236.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 229.2ms\n",
      "Speed: 2.4ms preprocess, 229.2ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 bowl, 245.0ms\n",
      "Speed: 2.4ms preprocess, 245.0ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 bowl, 244.1ms\n",
      "Speed: 1.3ms preprocess, 244.1ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 bowl, 240.7ms\n",
      "Speed: 1.9ms preprocess, 240.7ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 242.6ms\n",
      "Speed: 2.5ms preprocess, 242.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 hot_pad, 241.6ms\n",
      "Speed: 2.2ms preprocess, 241.6ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 232.8ms\n",
      "Speed: 2.7ms preprocess, 232.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 244.2ms\n",
      "Speed: 2.3ms preprocess, 244.2ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 245.3ms\n",
      "Speed: 1.9ms preprocess, 245.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 238.4ms\n",
      "Speed: 2.7ms preprocess, 238.4ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 258.4ms\n",
      "Speed: 2.3ms preprocess, 258.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 220.8ms\n",
      "Speed: 2.2ms preprocess, 220.8ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 245.2ms\n",
      "Speed: 2.3ms preprocess, 245.2ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 219.7ms\n",
      "Speed: 3.5ms preprocess, 219.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 242.6ms\n",
      "Speed: 2.7ms preprocess, 242.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 237.0ms\n",
      "Speed: 1.6ms preprocess, 237.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 236.6ms\n",
      "Speed: 2.2ms preprocess, 236.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 242.3ms\n",
      "Speed: 2.3ms preprocess, 242.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 237.3ms\n",
      "Speed: 2.7ms preprocess, 237.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 245.6ms\n",
      "Speed: 2.6ms preprocess, 245.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 239.5ms\n",
      "Speed: 4.2ms preprocess, 239.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 246.6ms\n",
      "Speed: 1.7ms preprocess, 246.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 235.6ms\n",
      "Speed: 3.2ms preprocess, 235.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 235.1ms\n",
      "Speed: 1.7ms preprocess, 235.1ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 242.6ms\n",
      "Speed: 2.0ms preprocess, 242.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 240.8ms\n",
      "Speed: 2.7ms preprocess, 240.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 253.3ms\n",
      "Speed: 2.5ms preprocess, 253.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 234.5ms\n",
      "Speed: 2.0ms preprocess, 234.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 219.3ms\n",
      "Speed: 2.9ms preprocess, 219.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 224.0ms\n",
      "Speed: 3.6ms preprocess, 224.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 243.8ms\n",
      "Speed: 1.5ms preprocess, 243.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 246.2ms\n",
      "Speed: 1.4ms preprocess, 246.2ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 246.1ms\n",
      "Speed: 2.9ms preprocess, 246.1ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 237.9ms\n",
      "Speed: 2.4ms preprocess, 237.9ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 220.0ms\n",
      "Speed: 1.6ms preprocess, 220.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 220.0ms\n",
      "Speed: 1.9ms preprocess, 220.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 238.4ms\n",
      "Speed: 2.2ms preprocess, 238.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 246.8ms\n",
      "Speed: 4.2ms preprocess, 246.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 240.9ms\n",
      "Speed: 2.2ms preprocess, 240.9ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 226.8ms\n",
      "Speed: 2.0ms preprocess, 226.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 244.5ms\n",
      "Speed: 1.7ms preprocess, 244.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 233.4ms\n",
      "Speed: 1.5ms preprocess, 233.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 251.4ms\n",
      "Speed: 2.2ms preprocess, 251.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 232.1ms\n",
      "Speed: 2.3ms preprocess, 232.1ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 240.7ms\n",
      "Speed: 3.9ms preprocess, 240.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 229.2ms\n",
      "Speed: 1.6ms preprocess, 229.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 243.4ms\n",
      "Speed: 1.5ms preprocess, 243.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 253.4ms\n",
      "Speed: 2.2ms preprocess, 253.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 247.3ms\n",
      "Speed: 1.7ms preprocess, 247.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 242.8ms\n",
      "Speed: 1.6ms preprocess, 242.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 255.8ms\n",
      "Speed: 1.6ms preprocess, 255.8ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 248.4ms\n",
      "Speed: 1.7ms preprocess, 248.4ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 234.8ms\n",
      "Speed: 1.6ms preprocess, 234.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 237.9ms\n",
      "Speed: 2.1ms preprocess, 237.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 236.2ms\n",
      "Speed: 2.1ms preprocess, 236.2ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 232.6ms\n",
      "Speed: 1.8ms preprocess, 232.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 243.3ms\n",
      "Speed: 1.8ms preprocess, 243.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 217.8ms\n",
      "Speed: 1.9ms preprocess, 217.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 237.5ms\n",
      "Speed: 2.4ms preprocess, 237.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 212.6ms\n",
      "Speed: 1.1ms preprocess, 212.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 225.4ms\n",
      "Speed: 1.8ms preprocess, 225.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 233.4ms\n",
      "Speed: 2.0ms preprocess, 233.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 253.8ms\n",
      "Speed: 3.9ms preprocess, 253.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 212.5ms\n",
      "Speed: 1.4ms preprocess, 212.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 231.4ms\n",
      "Speed: 2.2ms preprocess, 231.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 216.8ms\n",
      "Speed: 2.9ms preprocess, 216.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 235.9ms\n",
      "Speed: 4.1ms preprocess, 235.9ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 237.8ms\n",
      "Speed: 6.0ms preprocess, 237.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 240.9ms\n",
      "Speed: 2.4ms preprocess, 240.9ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 244.2ms\n",
      "Speed: 2.1ms preprocess, 244.2ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 257.8ms\n",
      "Speed: 5.2ms preprocess, 257.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 250.6ms\n",
      "Speed: 4.1ms preprocess, 250.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 260.7ms\n",
      "Speed: 3.9ms preprocess, 260.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 231.7ms\n",
      "Speed: 1.4ms preprocess, 231.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/evinjaff/github/oatmeal-cv-server/server/testVideo.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/evinjaff/github/oatmeal-cv-server/server/testVideo.ipynb#W4sZmlsZQ%3D%3D?line=296'>297</a>\u001b[0m         \u001b[39m# OUTPUT FRAME\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/evinjaff/github/oatmeal-cv-server/server/testVideo.ipynb#W4sZmlsZQ%3D%3D?line=297'>298</a>\u001b[0m         cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mOUTPUT\u001b[39m\u001b[39m\"\u001b[39m, finalImg)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/evinjaff/github/oatmeal-cv-server/server/testVideo.ipynb#W4sZmlsZQ%3D%3D?line=299'>300</a>\u001b[0m \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mq\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/evinjaff/github/oatmeal-cv-server/server/testVideo.ipynb#W4sZmlsZQ%3D%3D?line=300'>301</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/evinjaff/github/oatmeal-cv-server/server/testVideo.ipynb#W4sZmlsZQ%3D%3D?line=302'>303</a>\u001b[0m index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Video version\n",
    "# cap = cv2.VideoCapture(\n",
    "#     \"/Volumes/lconnor/Active/Patient_Recordings/50 Healthy Volunteers Video/AI007.mkv\"\n",
    "# )\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print(\"Error opening video file\")\n",
    "\n",
    "# cap = cv2.VideoCapture(\n",
    "#     \"/Volumes/lconnor-1/Active/Patient_Recordings/50 Healthy Volunteers Video/AI007.mkv\"\n",
    "# )\n",
    "\n",
    "w = int(cap.get(3))\n",
    "h = int(cap.get(4))\n",
    "fps = int(cap.get(5))\n",
    "\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "\n",
    "allItems = {\n",
    "    \"salt\": False,\n",
    "    \"timer\": False,\n",
    "    \"hot_pad\": False,\n",
    "    \"oatmeal\": False,\n",
    "    \"big_spoon\": False,\n",
    "    \"measuring_spoons\": False,\n",
    "    \"measuring_cup_1/2\": False,\n",
    "    \"measuring_cup_coffee\": False,\n",
    "    \"measuring_cup_full\": False,\n",
    "    \"measuring_cup_1/3\": False,\n",
    "    \"measuring_cup_1/4\": False,\n",
    "    \"tongs\": False,\n",
    "    \"scissors\": False,\n",
    "    \"spatula\": False,\n",
    "    \"bowl\": False,\n",
    "    \"pan\": False,\n",
    "    \"pepper\": False,\n",
    "    \"measuring_cup_glass\": False,\n",
    "    \"small_spoon\": False,\n",
    "    \"measuring_cup_group\": False,\n",
    "    \"glass\": False,\n",
    "}\n",
    "\n",
    "allRequired = {\n",
    "    \"salt\": False,\n",
    "    \"timer\": False,\n",
    "    \"hot_pad\": False,\n",
    "    \"oatmeal\": False,\n",
    "    \"big_spoon\": False,\n",
    "    \"measuring_spoons\": False,\n",
    "    \"measuring_cup_1/2\": False,\n",
    "    \"bowl\": False,\n",
    "    \"pan\": False,\n",
    "    \"measuring_cup_glass\": False,\n",
    "    \"small_spoon\": False,\n",
    "}\n",
    "\n",
    "allDistractors = {\n",
    "    \"measuring_cup_coffee\": False,\n",
    "    \"measuring_cup_full\": False,\n",
    "    \"measuring_cup_1/3\": False,\n",
    "    \"measuring_cup_1/4\": False,\n",
    "    \"tongs\": False,\n",
    "    \"scissors\": False,\n",
    "    \"spatula\": False,\n",
    "    \"pepper\": False,\n",
    "    \"measuring_cup_group\": False,\n",
    "    \"glass\": False,\n",
    "}\n",
    "\n",
    "index = 1\n",
    "start_time = time.time()\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    finalImg = frame\n",
    "    if ret == True:\n",
    "        if index % 60 == 0:\n",
    "            # extract only counter region\n",
    "            detectionRegion = frame[(h - 2 * h // 3 + 20) : h, 0:w, :]\n",
    "            regionH, regionW, regionC = detectionRegion.shape\n",
    "            cv2.rectangle(frame, (0, h - regionH), (regionW, h), (0, 255, 0), 4)\n",
    "\n",
    "            # get prediction\n",
    "            predictionObject = model(detectionRegion)\n",
    "\n",
    "            for allPreds in predictionObject:\n",
    "                for pred in allPreds:\n",
    "                    if np.array(pred.boxes.conf)[0] < 0.7:\n",
    "                        pass\n",
    "\n",
    "                    # get label\n",
    "                    labelNum = np.array(pred.boxes.cls)[0]\n",
    "                    labelName = allPreds.names[labelNum]\n",
    "\n",
    "                    # change item foundDictionaries to true\n",
    "                    if labelName in allRequired.keys():\n",
    "                        # reset timer if new item added\n",
    "                        if allRequired[labelName] == False:\n",
    "                            start_time = time.time()\n",
    "                        allRequired[labelName] = True\n",
    "                    if labelName in allDistractors.keys():\n",
    "                        allDistractors[labelName] = True\n",
    "\n",
    "                    # Draw bounding box for object\n",
    "                    box = np.array(pred.boxes.xyxy).flatten().astype(int)\n",
    "                    randomColor = tuple(np.random.random(size=3) * 256)\n",
    "                    cv2.rectangle(\n",
    "                        finalImg,\n",
    "                        (box[0], box[1] + h // 3 + 20),\n",
    "                        (box[2], box[3] + h // 3 + 20),\n",
    "                        randomColor,\n",
    "                        4,\n",
    "                    )\n",
    "                    (label_width, label_height), baseline = cv2.getTextSize(\n",
    "                        f\"{labelName}: {round(float(np.array(pred.boxes.conf)[0]), 2)}\",\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,\n",
    "                        2,\n",
    "                    )\n",
    "                    cv2.rectangle(\n",
    "                        finalImg,\n",
    "                        (box[0], box[1] + h // 3 + 20),\n",
    "                        (box[0] + label_width, box[1] + h // 3 + 20 - label_height),\n",
    "                        randomColor,\n",
    "                        -1,\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        finalImg,\n",
    "                        f\"{labelName}: {round(float(np.array(pred.boxes.conf)[0]), 2)}\",\n",
    "                        (box[0], box[1] + h // 3 + 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,\n",
    "                        (0, 0, 0),\n",
    "                        2,\n",
    "                        cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "                # ========= TEXT DISPLAY ========#\n",
    "                # Required Items\n",
    "                cv2.rectangle(finalImg, (0, 0), (540, h), (255, 255, 255), -1)\n",
    "                cv2.putText(\n",
    "                    finalImg,\n",
    "                    \"Required Items\",\n",
    "                    (0, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2,\n",
    "                    (255, 0, 0),\n",
    "                    4,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "\n",
    "                iter = 0\n",
    "                for k, v in allRequired.items():\n",
    "                    cv2.putText(\n",
    "                        finalImg,\n",
    "                        f\"{k}: \",\n",
    "                        (0, 50 + 40 + (30 * iter)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,\n",
    "                        (0, 0, 0),\n",
    "                        2,\n",
    "                        cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "                    (label_width, label_height), baseline = cv2.getTextSize(\n",
    "                        f\"{k}: \", cv2.FONT_HERSHEY_SIMPLEX, 1, 2\n",
    "                    )\n",
    "\n",
    "                    if v == True:\n",
    "                        cv2.putText(\n",
    "                            finalImg,\n",
    "                            \"PRESENT\",\n",
    "                            (0 + label_width, 50 + 40 + (30 * iter)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1,\n",
    "                            (0, 180, 0),\n",
    "                            2,\n",
    "                            cv2.LINE_AA,\n",
    "                        )\n",
    "                    else:\n",
    "                        cv2.putText(\n",
    "                            finalImg,\n",
    "                            \"ABSENT\",\n",
    "                            (0 + label_width, 50 + 40 + (30 * iter)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1,\n",
    "                            (0, 0, 255),\n",
    "                            2,\n",
    "                            cv2.LINE_AA,\n",
    "                        )\n",
    "                    iter += 1\n",
    "\n",
    "                # Distractor Items\n",
    "                cv2.putText(\n",
    "                    finalImg,\n",
    "                    \"Distractor Items\",\n",
    "                    (0, h - h // 2),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2,\n",
    "                    (255, 0, 0),\n",
    "                    4,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "\n",
    "                iter = 0\n",
    "                for k, v in allDistractors.items():\n",
    "                    cv2.putText(\n",
    "                        finalImg,\n",
    "                        f\"{k}: \",\n",
    "                        (0, h - h // 2 + 40 + (30 * iter)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,\n",
    "                        (0, 0, 0),\n",
    "                        2,\n",
    "                        cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "                    (label_width, label_height), baseline = cv2.getTextSize(\n",
    "                        f\"{k}: \", cv2.FONT_HERSHEY_SIMPLEX, 1, 2\n",
    "                    )\n",
    "\n",
    "                    if v == True:\n",
    "                        cv2.putText(\n",
    "                            finalImg,\n",
    "                            \"PRESENT\",\n",
    "                            (0 + label_width, h - h // 2 + 40 + (30 * iter)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1,\n",
    "                            (0, 180, 0),\n",
    "                            2,\n",
    "                            cv2.LINE_AA,\n",
    "                        )\n",
    "                    else:\n",
    "                        cv2.putText(\n",
    "                            finalImg,\n",
    "                            \"ABSENT\",\n",
    "                            (0 + label_width, h - h // 2 + 40 + (30 * iter)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1,\n",
    "                            (0, 0, 255),\n",
    "                            2,\n",
    "                            cv2.LINE_AA,\n",
    "                        )\n",
    "                    iter += 1\n",
    "\n",
    "                # ITEM LIST STATE CHECKS\n",
    "                if all(value for value in allRequired.values()):\n",
    "                    # all required and no distractors\n",
    "                    if not any(value for value in allDistractors.values()):\n",
    "                        drawBackgroundText(\n",
    "                            finalImg,\n",
    "                            w,\n",
    "                            50,\n",
    "                            \"MOVING TO ACTION DETECTION\",\n",
    "                            (255, 0, 0),\n",
    "                            2,\n",
    "                            4,\n",
    "                        )\n",
    "                    # all required and some distractors\n",
    "                    else:\n",
    "                        drawBackgroundText(\n",
    "                            finalImg,\n",
    "                            w,\n",
    "                            50,\n",
    "                            \"Anything you don't need?\",\n",
    "                            (255, 0, 0),\n",
    "                            2,\n",
    "                            4,\n",
    "                        )\n",
    "                else:\n",
    "                    elapsed_time = start_time - time.time()\n",
    "                    if elapsed_time >= 8:\n",
    "                        drawBackgroundText(\n",
    "                            finalImg,\n",
    "                            w,\n",
    "                            50,\n",
    "                            \"Are you missing something?\",\n",
    "                            (255, 0, 0),\n",
    "                            2,\n",
    "                            4,\n",
    "                        )\n",
    "                        start_time = time.time()\n",
    "\n",
    "                    else:\n",
    "                        drawBackgroundText(\n",
    "                            finalImg,\n",
    "                            w,\n",
    "                            50,\n",
    "                            \"PARTICIPANT STILL PICKING\",\n",
    "                            (255, 0, 0),\n",
    "                            2,\n",
    "                            4,\n",
    "                        )\n",
    "\n",
    "                # OUTPUT FRAME\n",
    "                cv2.imshow(\"OUTPUT\", finalImg)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        index += 1\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
